# Psych239 Final project

# Optimizing latent representation of self-supervised models: Inspired by the hippocampus

## Introduction

Artificial intelligence (AI) has rapidly developed in the fast few decades to the extent of outperforming humans on certain tasks [[1](arxiv.org/abs/2010.03449)]. However, artificial general intelligence (GAI?) is yet to be realized because the expertise of AI models is confined to narrowly-defined tasks such as visual classification or signal detection, but even the state-of-the-art (SOTA) models lack generalizability; for example, if it is trained in a supervised manner, a machine cannot learn beyond labels that were imposed or defined by humans. Since labeling or refining data is a time- and resource-costly task, methods beyond supervised learning should be sought for GAI. 

Recently, various self-supervised learning methods have been proposed to overcome this issue. In the domain of computer vision, for example, transfer learning, which takes lower-level weights from pre-trained models and fine-tune the weights to adapt to a novel task, has been proposed as a means of generalizing AI [cite]. One of the most recently proposed models is SimCLR [cite]. The gist of this model is a pretext task that trains the model to minimize the within-class representation as well as maximize between-class representation without class labels. First, a batch of different objects are created, and then one image (e.g., a cat) is selected within the batch. Data augmentation methods such as cropping, zooming, or changes to RGB values are performed so that the augmented image seems to be a different exemplar from the same group of the original image (e.g., another cat). By this procedure, the unique feature of a class is stored within a latent vector, and the learned latent vectors are used for further visualization tasks. SimCLR has achieved SOTA performance of XX % in visual classification tasks using XX. 

However, even if generalization of visual classification tasks is fully achieved, it would still not be the ultimate goal of GAI because in real life without incorporating reinforcement learning (RL). This is because organisms perform these two tasks simultaneously – for example, when humans go shopping for grocery, they perform visual recognition tasks and reinforcement learning at the same time – together with other tasks. The ultimate form of GAI will have to incorporate RL at some point because it provides the foundation of learning which options lead to more value in a continuous environment, leading to key for survival. 

RL, however, also faces similar difficulties in generalization. One such difficulty is weak inductive bias (소심한 개발자; Botvinick et. al, 2019): updating parameters through small learning steps and numerous samples for generalization (e.g., learning so that an agent can choose the optimal action upon encountering a new state) is inefficient compared to recalling “episodic memory” of previously experienced similar states and averaging them. To overcome this inefficiency, episodic control has been proposed (Lengyel & Dayan 2008). Inspired by the instance-based hippocampal learning, this method retains memories of the events in the past and utilizes them upon encountering a state which requires new actions. In one such method, model-free episodic control (MFEC; Blundell et. al, 2016), each episodic memory is saved as a key-value pair in a table, where state-action pair is the key and its Q-value is the value. The Q-value of a new, unexperienced state is estimated by averaging the Q-values of the previously encountered states. However, this form of tabular RL in MFEC results in memory consumption, since the amount of information that can be stored in a table is finite. Neural episodic control (Pritzel et. al, 2016) seeks to overcome memory consumption and improve generalization between similar states by using least recently used (LRU) cache. Here, episodic memory is stored in a differentiable neural dictionary (DND) in a key-value pair, where key is the convolutional embedding vector of the input pixel image and the value is the Q-value of the state. In order to estimate the Q-value of an encountered state, the weighted sum of the Q-values of most similar keys is returned as the output. Here, the weight is derived by normalizing the kernel measure between the query key and the keys in the dictionary.  

In this study, I aim to provide a link between the two precursors of GAI – self-supervised learning and memory-based RL – through a key feature they share: the latent vector. Specifically, I claim that SimCLR’s contrastive learning strategy (maximizing the representational similarity within class and dissimilarity between class at the same time) resembles hippocampal pattern completion [cite]. When memory is formed, two opposing strategies – pattern completion and pattern separation – happens in the hippocampus to achieve generalization of instances and identifying a specific instance at the same time. Pattern completion happens in CA3 and contributes to generalization of instances by encoding an engram, whereas pattern separation in the dentate gyrus (DG) aims to minimize interference of similar instances by orthogonal encoding [cite: Lee et. al 2015 Neuron]. SimCLR’s latent vector can be compared to the pattern completion in the HC, since they both seek a common representation between similar instances. However, minimizing interferences between similar instances should also be considered for GAI models, since identification of individual episodes might become important for future RL paradigms that take place in a more real-life context. In this study, I propose a modified version of SimCLR that achieves pattern completion and separation at the same time. Specifically, I hypothesize that (1) the proposed model will show comparable performance to the original SimCLR and (2) the proposed model will produce more separable latent vectors for similar instances while retaining the difference between classes. 
