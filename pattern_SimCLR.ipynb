{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pattern_SimCLR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWmSgB39ZG5ZoJv/YgEhuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoojungsun0/Psych239/blob/master/pattern_SimCLR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9CzNhIZsnOl",
        "outputId": "0529cdfd-040c-40bb-af55-e5fd145bd7af"
      },
      "source": [
        "!git clone https://github.com/yoojungsun0/Psych239.git\n",
        "\n",
        "!pip install thop"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Psych239'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "Collecting thop\n",
            "  Downloading https://files.pythonhosted.org/packages/6c/8b/22ce44e1c71558161a8bd54471123cc796589c7ebbfc15a7e8932e522f83/thop-0.0.31.post2005241907-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from thop) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.16.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.0.31.post2005241907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ikfzIt5adK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93982f59-5d17-4eb2-bc42-bd476c823c2d"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from thop import profile, clever_format\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# import utils\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "import sys\n",
        "%cd /content/gdrive/MyDrive/'Colab Notebooks'/SimCLR\n",
        "from model import Model\n",
        "import utils\n",
        "import linear\n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/MyDrive/Colab Notebooks/SimCLR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHvHgKJ460Ng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ReeC9qwvpsL"
      },
      "source": [
        "# train for one epoch to learn unique features\n",
        "def train(net, data_loader, train_optimizer):\n",
        "    net.train()\n",
        "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
        "    for pos_1, pos_2, target in train_bar:\n",
        "        pos_1, pos_2 = pos_1.cuda(non_blocking=True), pos_2.cuda(non_blocking=True)\n",
        "        feature_1, out_1 = net(pos_1)\n",
        "        feature_2, out_2 = net(pos_2)\n",
        "        # [2*B, D]\n",
        "        out = torch.cat([out_1, out_2], dim=0)\n",
        "        # [2*B, 2*B]\n",
        "        sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
        "        mask = (torch.ones_like(sim_matrix) - torch.eye(2 * batch_size, device=sim_matrix.device)).bool()\n",
        "        # [2*B, 2*B-1]\n",
        "        sim_matrix = sim_matrix.masked_select(mask).view(2 * batch_size, -1)\n",
        "\n",
        "        # compute loss\n",
        "        pos_sim = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
        "        # [2*B]\n",
        "        pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n",
        "        loss = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean()\n",
        "        train_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_optimizer.step()\n",
        "\n",
        "        total_num += batch_size\n",
        "        total_loss += loss.item() * batch_size\n",
        "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
        "\n",
        "    return total_loss / total_num\n",
        "\n",
        "def train_separation(net, data_loader, train_optimizer, gamma):\n",
        "    net.train()\n",
        "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
        "    for pos_1, pos_2, target in train_bar:\n",
        "        pos_1, pos_2 = pos_1.cuda(non_blocking=True), pos_2.cuda(non_blocking=True)\n",
        "        feature_1, out_1 = net(pos_1)\n",
        "        feature_2, out_2 = net(pos_2)\n",
        "        # [2*B, D]\n",
        "        out = torch.cat([out_1, out_2], dim=0)\n",
        "        # [2*B, 2*B]\n",
        "        sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
        "        mask = (torch.ones_like(sim_matrix) - torch.eye(2 * batch_size, device=sim_matrix.device)).bool()\n",
        "        # [2*B, 2*B-1]\n",
        "        sim_matrix = sim_matrix.masked_select(mask).view(2 * batch_size, -1)\n",
        "\n",
        "        # compute loss\n",
        "        pos_sim = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
        "        # [2*B]\n",
        "        pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n",
        "        loss1 = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean()\n",
        "\n",
        "        # loss for learning pattern separation\n",
        "        # pos_dis = distance between out_1 and out_2\n",
        "        pos_dis = out_1 - out_2\n",
        "        pos_dis = torch.square(pos_dis)\n",
        "        pos_dis = torch.sum(pos_dis)\n",
        "        pos_dis = torch.sqrt(pos_dis)\n",
        "        pos_dis = pos_dis.sum(dim=-1)\n",
        "\n",
        "        loss2 = - torch.log(pos_dis)\n",
        "\n",
        "\n",
        "        loss = loss1 + (loss2 * gamma)\n",
        "\n",
        "        train_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_optimizer.step()\n",
        "\n",
        "        total_num += batch_size\n",
        "        total_loss += loss.item() * batch_size\n",
        "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
        "\n",
        "    return total_loss / total_num\n",
        "\n",
        "# test for one epoch, use weighted knn to find the most similar images' label to assign the test image\n",
        "def test(net, memory_data_loader, test_data_loader):\n",
        "    net.eval()\n",
        "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
        "    with torch.no_grad():\n",
        "        # generate feature bank\n",
        "        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n",
        "            feature, out = net(data.cuda(non_blocking=True))\n",
        "            feature_bank.append(feature)\n",
        "        # [D, N]\n",
        "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
        "        # [N]\n",
        "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
        "        # loop test data to predict the label by weighted knn search\n",
        "        test_bar = tqdm(test_data_loader)\n",
        "        for data, _, target in test_bar:\n",
        "            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
        "            feature, out = net(data)\n",
        "\n",
        "            total_num += data.size(0)\n",
        "            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
        "            sim_matrix = torch.mm(feature, feature_bank)\n",
        "            # [B, K]\n",
        "            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n",
        "            # [B, K]\n",
        "            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n",
        "            sim_weight = (sim_weight / temperature).exp()\n",
        "\n",
        "            # counts for each class\n",
        "            one_hot_label = torch.zeros(data.size(0) * k, c, device=sim_labels.device)\n",
        "            # [B*K, C]\n",
        "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
        "            # weighted score ---> [B, C]\n",
        "            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
        "\n",
        "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
        "            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n",
        "                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n",
        "\n",
        "    return total_top1 / total_num * 100, total_top5 / total_num * 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV1cWOGov3uo"
      },
      "source": [
        "# parameters \n",
        "\n",
        "feature_dim = 128\n",
        "temperature = 0.5\n",
        "k = 200\n",
        "# batch_size = 512\n",
        "# epochs = 500\n",
        "batch_size = 256\n",
        "epochs = 100\n",
        "\n",
        "# yjs added\n",
        "gamma = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ocZCFibw5Zd",
        "outputId": "3849ecee-7be8-4fbf-cc2a-03406a8628b6"
      },
      "source": [
        "# data prepare\n",
        "train_data = utils.CIFAR10Pair(root='data', train=True, transform=utils.train_transform, download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True,\n",
        "                          drop_last=True)\n",
        "memory_data = utils.CIFAR10Pair(root='data', train=True, transform=utils.test_transform, download=True)\n",
        "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "test_data = utils.CIFAR10Pair(root='data', train=False, transform=utils.test_transform, download=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "\n",
        "# model setup and optimizer config\n",
        "model = Model(feature_dim).cuda()\n",
        "flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n",
        "flops, params = clever_format([flops, params])\n",
        "print('# Model Params: {} FLOPs: {}'.format(params, flops))\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "c = len(memory_data.classes)\n",
        "\n",
        "# training loop\n",
        "results = {'train_loss': [], 'test_acc@1': [], 'test_acc@5': []}\n",
        "save_name_pre = '{}_{}_{}_{}_{}'.format(feature_dim, temperature, k, batch_size, epochs)\n",
        "if not os.path.exists('results'):\n",
        "    os.mkdir('results')\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # train_loss = train(model, train_loader, optimizer)\n",
        "    train_loss = train_separation(model, train_loader, optimizer, gamma)\n",
        "    results['train_loss'].append(train_loss)\n",
        "    test_acc_1, test_acc_5 = test(model, memory_loader, test_loader)\n",
        "    results['test_acc@1'].append(test_acc_1)\n",
        "    results['test_acc@5'].append(test_acc_5)\n",
        "    # save statistics\n",
        "    data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n",
        "    data_frame.to_csv('results/{}_statistics.csv'.format(save_name_pre), index_label='epoch')\n",
        "    if test_acc_1 > best_acc:\n",
        "        best_acc = test_acc_1\n",
        "        torch.save(model.state_dict(), 'results/{}_model.pth'.format(save_name_pre))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/195 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'model.Model'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "# Model Params: 24.62M FLOPs: 1.31G\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: [1/100] Loss: 4.9326: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [1/100] Acc@1:43.77% Acc@5:91.12%: 100%|██████████| 40/40 [00:12<00:00,  3.22it/s]\n",
            "Train Epoch: [2/100] Loss: 4.7119: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.12it/s]\n",
            "Test Epoch: [2/100] Acc@1:45.69% Acc@5:92.16%: 100%|██████████| 40/40 [00:12<00:00,  3.21it/s]\n",
            "Train Epoch: [3/100] Loss: 4.6362: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [3/100] Acc@1:48.62% Acc@5:93.00%: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n",
            "Train Epoch: [4/100] Loss: 4.5749: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [4/100] Acc@1:50.70% Acc@5:93.65%: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
            "Train Epoch: [5/100] Loss: 4.5342: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [5/100] Acc@1:52.59% Acc@5:94.28%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [6/100] Loss: 4.5006: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [6/100] Acc@1:54.45% Acc@5:95.07%: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
            "Train Epoch: [7/100] Loss: 4.4719: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [7/100] Acc@1:55.97% Acc@5:95.63%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [8/100] Loss: 4.4506: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [8/100] Acc@1:57.88% Acc@5:96.36%: 100%|██████████| 40/40 [00:12<00:00,  3.17it/s]\n",
            "Train Epoch: [9/100] Loss: 4.4325: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [9/100] Acc@1:58.90% Acc@5:96.85%: 100%|██████████| 40/40 [00:12<00:00,  3.21it/s]\n",
            "Train Epoch: [10/100] Loss: 4.4218: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [10/100] Acc@1:59.87% Acc@5:96.69%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [11/100] Loss: 4.4044: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [11/100] Acc@1:62.09% Acc@5:96.93%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [12/100] Loss: 4.3955: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [12/100] Acc@1:62.55% Acc@5:97.07%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [13/100] Loss: 4.3874: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.11it/s]\n",
            "Test Epoch: [13/100] Acc@1:63.61% Acc@5:97.19%: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n",
            "Train Epoch: [14/100] Loss: 4.3833: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [14/100] Acc@1:64.82% Acc@5:97.37%: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n",
            "Train Epoch: [15/100] Loss: 4.3743: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [15/100] Acc@1:65.53% Acc@5:97.63%: 100%|██████████| 40/40 [00:12<00:00,  3.21it/s]\n",
            "Train Epoch: [16/100] Loss: 4.3687: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [16/100] Acc@1:66.55% Acc@5:97.66%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [17/100] Loss: 4.3622: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [17/100] Acc@1:68.31% Acc@5:97.92%: 100%|██████████| 40/40 [00:12<00:00,  3.22it/s]\n",
            "Train Epoch: [18/100] Loss: 4.3563: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.12it/s]\n",
            "Test Epoch: [18/100] Acc@1:67.68% Acc@5:97.78%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [19/100] Loss: 4.3534: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [19/100] Acc@1:67.94% Acc@5:97.88%: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n",
            "Train Epoch: [20/100] Loss: 4.3484: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [20/100] Acc@1:69.11% Acc@5:97.96%: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
            "Train Epoch: [21/100] Loss: 4.3430: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [21/100] Acc@1:69.43% Acc@5:98.01%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [22/100] Loss: 4.3422: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [22/100] Acc@1:69.17% Acc@5:98.02%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [23/100] Loss: 4.3348: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.12it/s]\n",
            "Test Epoch: [23/100] Acc@1:69.30% Acc@5:98.05%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [24/100] Loss: 4.3341: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [24/100] Acc@1:70.59% Acc@5:98.10%: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n",
            "Train Epoch: [25/100] Loss: 4.3353: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [25/100] Acc@1:70.74% Acc@5:98.12%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [26/100] Loss: 4.3280: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.17it/s]\n",
            "Test Epoch: [26/100] Acc@1:70.99% Acc@5:98.28%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [27/100] Loss: 4.3257: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.17it/s]\n",
            "Test Epoch: [27/100] Acc@1:70.88% Acc@5:98.17%: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n",
            "Train Epoch: [28/100] Loss: 4.3181: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [28/100] Acc@1:71.04% Acc@5:98.33%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [29/100] Loss: 4.3184: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [29/100] Acc@1:72.05% Acc@5:98.45%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [30/100] Loss: 4.3183: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.18it/s]\n",
            "Test Epoch: [30/100] Acc@1:72.04% Acc@5:98.33%: 100%|██████████| 40/40 [00:12<00:00,  3.30it/s]\n",
            "Train Epoch: [31/100] Loss: 4.3123: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [31/100] Acc@1:72.30% Acc@5:98.35%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [32/100] Loss: 4.3143: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [32/100] Acc@1:72.58% Acc@5:98.40%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [33/100] Loss: 4.3117: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.17it/s]\n",
            "Test Epoch: [33/100] Acc@1:72.75% Acc@5:98.41%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [34/100] Loss: 4.3062: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [34/100] Acc@1:73.14% Acc@5:98.41%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [35/100] Loss: 4.3026: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [35/100] Acc@1:72.80% Acc@5:98.36%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [36/100] Loss: 4.3022: 100%|██████████| 195/195 [06:13<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [36/100] Acc@1:72.21% Acc@5:98.34%: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n",
            "Train Epoch: [37/100] Loss: 4.2981: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [37/100] Acc@1:73.53% Acc@5:98.52%: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
            "Train Epoch: [38/100] Loss: 4.2986: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.13it/s]\n",
            "Test Epoch: [38/100] Acc@1:73.74% Acc@5:98.50%: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
            "Train Epoch: [39/100] Loss: 4.2949: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [39/100] Acc@1:73.47% Acc@5:98.56%: 100%|██████████| 40/40 [00:12<00:00,  3.30it/s]\n",
            "Train Epoch: [40/100] Loss: 4.2931: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.17it/s]\n",
            "Test Epoch: [40/100] Acc@1:74.02% Acc@5:98.50%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [41/100] Loss: 4.2933: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [41/100] Acc@1:73.95% Acc@5:98.38%: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
            "Train Epoch: [42/100] Loss: 4.2922: 100%|██████████| 195/195 [06:13<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [42/100] Acc@1:74.08% Acc@5:98.64%: 100%|██████████| 40/40 [00:12<00:00,  3.30it/s]\n",
            "Train Epoch: [43/100] Loss: 4.2889: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [43/100] Acc@1:75.02% Acc@5:98.64%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [44/100] Loss: 4.2887: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [44/100] Acc@1:75.16% Acc@5:98.74%: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n",
            "Train Epoch: [45/100] Loss: 4.2844: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.17it/s]\n",
            "Test Epoch: [45/100] Acc@1:74.94% Acc@5:98.48%: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n",
            "Train Epoch: [46/100] Loss: 4.2880: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [46/100] Acc@1:74.83% Acc@5:98.58%: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n",
            "Train Epoch: [47/100] Loss: 4.2816: 100%|██████████| 195/195 [06:13<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.17it/s]\n",
            "Test Epoch: [47/100] Acc@1:74.97% Acc@5:98.56%: 100%|██████████| 40/40 [00:12<00:00,  3.30it/s]\n",
            "Train Epoch: [48/100] Loss: 4.2794: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [48/100] Acc@1:74.68% Acc@5:98.52%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [49/100] Loss: 4.2778: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [49/100] Acc@1:75.21% Acc@5:98.54%: 100%|██████████| 40/40 [00:12<00:00,  3.22it/s]\n",
            "Train Epoch: [50/100] Loss: 4.2779: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [50/100] Acc@1:75.18% Acc@5:98.73%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [51/100] Loss: 4.2782: 100%|██████████| 195/195 [06:13<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.14it/s]\n",
            "Test Epoch: [51/100] Acc@1:75.26% Acc@5:98.61%: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n",
            "Train Epoch: [52/100] Loss: 4.2754: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.18it/s]\n",
            "Test Epoch: [52/100] Acc@1:75.77% Acc@5:98.65%: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n",
            "Train Epoch: [53/100] Loss: 4.2734: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.17it/s]\n",
            "Test Epoch: [53/100] Acc@1:75.76% Acc@5:98.63%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [54/100] Loss: 4.2740: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.18it/s]\n",
            "Test Epoch: [54/100] Acc@1:76.08% Acc@5:98.53%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [55/100] Loss: 4.2737: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.18it/s]\n",
            "Test Epoch: [55/100] Acc@1:75.41% Acc@5:98.52%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [56/100] Loss: 4.2702: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [56/100] Acc@1:75.99% Acc@5:98.59%: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
            "Train Epoch: [57/100] Loss: 4.2700: 100%|██████████| 195/195 [06:13<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [57/100] Acc@1:76.07% Acc@5:98.59%: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n",
            "Train Epoch: [58/100] Loss: 4.2688: 100%|██████████| 195/195 [06:13<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.19it/s]\n",
            "Test Epoch: [58/100] Acc@1:76.46% Acc@5:98.70%: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s]\n",
            "Train Epoch: [59/100] Loss: 4.2697: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [59/100] Acc@1:76.80% Acc@5:98.80%: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
            "Train Epoch: [60/100] Loss: 4.2651: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [60/100] Acc@1:76.91% Acc@5:98.84%: 100%|██████████| 40/40 [00:12<00:00,  3.20it/s]\n",
            "Train Epoch: [61/100] Loss: 4.2638: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [61/100] Acc@1:76.54% Acc@5:98.76%: 100%|██████████| 40/40 [00:12<00:00,  3.20it/s]\n",
            "Train Epoch: [62/100] Loss: 4.2653: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [62/100] Acc@1:76.57% Acc@5:98.63%: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n",
            "Train Epoch: [63/100] Loss: 4.2612: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [63/100] Acc@1:76.89% Acc@5:98.70%: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n",
            "Train Epoch: [64/100] Loss: 4.2592: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [64/100] Acc@1:77.39% Acc@5:98.80%: 100%|██████████| 40/40 [00:12<00:00,  3.29it/s]\n",
            "Train Epoch: [65/100] Loss: 4.2596: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.15it/s]\n",
            "Test Epoch: [65/100] Acc@1:77.06% Acc@5:98.70%: 100%|██████████| 40/40 [00:12<00:00,  3.22it/s]\n",
            "Train Epoch: [66/100] Loss: 4.2573: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [66/100] Acc@1:77.74% Acc@5:98.89%: 100%|██████████| 40/40 [00:12<00:00,  3.20it/s]\n",
            "Train Epoch: [67/100] Loss: 4.2588: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [67/100] Acc@1:77.51% Acc@5:98.94%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [68/100] Loss: 4.2565: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.17it/s]\n",
            "Test Epoch: [68/100] Acc@1:77.58% Acc@5:98.66%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [69/100] Loss: 4.2565: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [69/100] Acc@1:77.94% Acc@5:98.97%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [70/100] Loss: 4.2584: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [70/100] Acc@1:77.89% Acc@5:98.88%: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n",
            "Train Epoch: [71/100] Loss: 4.2547: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:47<00:00,  4.16it/s]\n",
            "Test Epoch: [71/100] Acc@1:78.22% Acc@5:98.97%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [72/100] Loss: 4.2549: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.17it/s]\n",
            "Test Epoch: [72/100] Acc@1:77.45% Acc@5:98.85%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [73/100] Loss: 4.2525: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.19it/s]\n",
            "Test Epoch: [73/100] Acc@1:78.31% Acc@5:98.93%: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n",
            "Train Epoch: [74/100] Loss: 4.2526: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.18it/s]\n",
            "Test Epoch: [74/100] Acc@1:78.33% Acc@5:98.93%: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
            "Train Epoch: [75/100] Loss: 4.2499: 100%|██████████| 195/195 [06:14<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.17it/s]\n",
            "Test Epoch: [75/100] Acc@1:78.54% Acc@5:98.92%: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s]\n",
            "Train Epoch: [76/100] Loss: 4.2496: 100%|██████████| 195/195 [06:13<00:00,  1.92s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.18it/s]\n",
            "Test Epoch: [76/100] Acc@1:78.44% Acc@5:98.95%: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
            "Train Epoch: [77/100] Loss: 4.2506: 100%|██████████| 195/195 [06:12<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.20it/s]\n",
            "Test Epoch: [77/100] Acc@1:78.42% Acc@5:98.95%: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
            "Train Epoch: [78/100] Loss: 4.2442: 100%|██████████| 195/195 [06:11<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.21it/s]\n",
            "Test Epoch: [78/100] Acc@1:78.44% Acc@5:98.93%: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
            "Train Epoch: [79/100] Loss: 4.2468: 100%|██████████| 195/195 [06:12<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.20it/s]\n",
            "Test Epoch: [79/100] Acc@1:78.85% Acc@5:98.92%: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
            "Train Epoch: [80/100] Loss: 4.2454: 100%|██████████| 195/195 [06:12<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.22it/s]\n",
            "Test Epoch: [80/100] Acc@1:79.53% Acc@5:98.99%: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
            "Train Epoch: [81/100] Loss: 4.2445: 100%|██████████| 195/195 [06:12<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.19it/s]\n",
            "Test Epoch: [81/100] Acc@1:79.38% Acc@5:99.08%: 100%|██████████| 40/40 [00:12<00:00,  3.33it/s]\n",
            "Train Epoch: [82/100] Loss: 4.2443: 100%|██████████| 195/195 [06:11<00:00,  1.91s/it]\n",
            "Feature extracting: 100%|██████████| 196/196 [00:46<00:00,  4.19it/s]\n",
            "Test Epoch: [82/100] Acc@1:79.05% Acc@5:98.96%: 100%|██████████| 40/40 [00:12<00:00,  3.31it/s]\n",
            "Train Epoch: [83/100] Loss: 4.2450: 100%|██████████| 195/195 [06:11<00:00,  1.91s/it]\n",
            "Feature extracting:  95%|█████████▌| 187/196 [00:44<00:02,  4.29it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2_QpYAK5y_-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "e3fcdc6d-ae9d-4117-e647-d3256fd57ea4"
      },
      "source": [
        "while True:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-648a2bab0435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVKU6l9c61V-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}